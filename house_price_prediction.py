# -*- coding: utf-8 -*-
"""house-price-prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KT485QV52LODH1kEpRfHw_DexmNB5cgv

# House price prediction
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing the libraries
import pandas as pd
import numpy as np
from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

#importing the dataset
from sklearn.datasets import fetch_california_housing
california = fetch_california_housing()

# Initializing the dataframe
data = pd.DataFrame(california.data)

# See head of the dataset
data.head()

#Adding the feature names to the dataframe
data.columns = california.feature_names
data.head()

"""Each record in the database describes a Boston suburb or town."""

#Adding target variable to dataframe
data['PRICE'] = california.target

#Check the shape of dataframe
data.shape

data.columns

data.dtypes

# Identifying the unique number of values in the dataset
data.nunique()

# Check for missing values
data.isnull().sum()

# See rows with missing values
data[data.isnull().any(axis=1)]

# Viewing the data statistics
data.describe()

# Finding out the correlation between the features
corr = data.corr()
corr.shape

# Plotting the heatmap of correlation between features
plt.figure(figsize=(20,20))
sns.heatmap(corr, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap='Greens')

"""**Outlier detection**"""

# Choose the feature(s) you want to perform outlier detection on
feature_of_interest = 'PRICE'

z_scores = np.abs((data[feature_of_interest] - data[feature_of_interest].mean()) / data[feature_of_interest].std())

threshold = 3

outliers = data[z_scores > threshold]


print("Outliers:")
print(outliers)

"""# Linear regression

#### Training the model
"""

from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd

X = data.drop(columns=['PRICE'])
y = data['PRICE']
# Assuming you have a feature matrix X and target vector y
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the parameter grid for alpha values to search
param_grid = {'alpha': np.logspace(-3, 3, 7)}

# Create the Lasso regression model
lasso = Lasso()

# Perform grid search with cross-validation
grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)

# Get the best hyperparameter value
best_alpha = grid_search.best_params_['alpha']

# Train the final model with the best hyperparameter
final_model = Lasso(alpha=best_alpha)
final_model.fit(X_train, y_train)

# Evaluate the final model on the test set
y_pred = final_model.predict(X_test)

"""#### Model Evaluation"""

# Model Evaluation
print('R^2:',metrics.r2_score(y_test, y_pred))
print('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_train.shape[1]-1))
print('MAE:',metrics.mean_absolute_error(y_test, y_pred))
print('MSE:',metrics.mean_squared_error(y_test, y_pred))
print('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

"""ùëÖ^2 : It is a measure of the linear relationship between X and Y. It is interpreted as the proportion of the variance in the dependent variable that is predictable from the independent variable.

Adjusted ùëÖ^2 :The adjusted R-squared compares the explanatory power of regression models that contain different numbers of predictors.

MAE : It is the mean of the absolute value of the errors. It measures the difference between two continuous variables, here actual and predicted values of y.

MSE: The¬†mean square error¬†(MSE) is just like the MAE, but¬†squares¬†the difference before summing them all instead of using the absolute value.

RMSE: The¬†mean square error¬†(MSE) is just like the MAE, but¬†squares¬†the difference before summing them all instead of using the absolute value.





"""

import matplotlib.pyplot as plt

# Scatter plot for actual prices (blue color)
plt.scatter(y_test, y_test, c='b', label='Actual Price', marker='o')

# Scatter plot for predicted prices (red color)
plt.scatter(y_test, y_pred, c='r', label='Predicted Prices', marker='x')

plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs Predicted Prices')
plt.legend()
plt.grid()
plt.show()

# Checking residuals
plt.scatter(y_test,y_pred)
plt.title("Predicted vs residuals")
plt.xlabel("Predicted")
plt.ylabel("Residuals")
plt.show()

"""# Random Forest Regressor"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV
import numpy as np

# Define the parameter grid for random search
param_grid = {
    'n_estimators': [10, 20, 30, 40, 50],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth': [10, 10, 10, 10, 10, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Create a Random Forest Regressor
rf = RandomForestRegressor()

# Perform random search with cross-validation
random_search = RandomizedSearchCV(rf, param_distributions=param_grid, n_iter=50, cv=5, scoring='neg_mean_squared_error', random_state=42)
random_search.fit(X_train, y_train)

# Get the best hyperparameters
best_params = random_search.best_params_
best_score = -random_search.best_score_

# Fit the model with the best hyperparameters
best_rf = RandomForestRegressor(**best_params)
best_rf.fit(X_train, y_train)

# Evaluate the best model
y_pred = best_rf.predict(X_test)

# Calculate metrics on the test data
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Best Hyperparameters:", best_params)
print("Best Negative MSE (Cross-Validation):", best_score)
print("Mean Squared Error (MSE) on Test Data:", mse)
print("Mean Absolute Error (MAE) on Test Data:", mae)
print("R-squared (R2) Score on Test Data:", r2)

"""### Model Evaluation"""

# Visualizing the differences between actual prices and predicted values
plt.scatter(y_test, y_test, c='b', label='Actual Price', marker='o')

# Scatter plot for predicted prices (red color)
plt.scatter(y_test, y_pred, c='r', label='Predicted Prices', marker='x', alpha= 0.5)
plt.xlabel("Prices")
plt.ylabel("Predicted prices")
plt.title("Prices vs Predicted prices")
plt.show()

"""#### For test data

# SVM Regressor
"""

# Creating scaled set to be used in model to improve our results
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""#### Train the model"""

# Import SVM Regressor
from sklearn import svm

# Create a SVM Regressor
reg = svm.SVR()

# Train the model using the training sets
reg.fit(X_train, y_train)

"""#### Model Evaluation"""

# Model prediction on train data
y_pred = reg.predict(X_train)

# Model Evaluation
print('R^2:',metrics.r2_score(y_train, y_pred))
print('Adjusted R^2:',1 - (1-metrics.r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1))
print('MAE:',metrics.mean_absolute_error(y_train, y_pred))
print('MSE:',metrics.mean_squared_error(y_train, y_pred))
print('RMSE:',np.sqrt(metrics.mean_squared_error(y_train, y_pred)))

plt.scatter(y_train, y_train, c='b', label='Actual Price', marker='o')
plt.scatter(y_train, y_pred, c='r', label='Predicted Prices', marker='x' ,alpha= 0.2)
plt.xlabel("Prices")
plt.ylabel("Predicted prices")
plt.title("Prices vs Predicted prices")
plt.show()

"""#### For test data"""

# Predicting Test data with the model
y_test_pred = reg.predict(X_test)

# Model Evaluation
acc_svm = metrics.r2_score(y_test, y_test_pred)
print('R^2:', acc_svm)
print('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_test_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))
print('MAE:',metrics.mean_absolute_error(y_test, y_test_pred))
print('MSE:',metrics.mean_squared_error(y_test, y_test_pred))
print('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))

plt.scatter(y_test, y_test, c='b', label='Actual Price', marker='o')
plt.scatter(y_test, y_test_pred, c='r', label='Predicted Prices', marker='x')
plt.xlabel("Prices")
plt.ylabel("Predicted prices")
plt.title("Prices vs Predicted prices")
plt.show()